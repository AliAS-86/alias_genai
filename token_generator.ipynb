{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'Ġam', 'Ġthe', 'Ġcaptain', 'Ġof', 'Ġmy']\n",
      "{'input_ids': tensor([[   40,   716,   262, 10654,   286,   616]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "dense vector: tensor([[ 0.1474, -0.0959,  0.1430,  ...,  0.1030, -0.0625, -0.1131],\n",
      "        [ 0.1596, -0.1249,  0.1148,  ...,  0.2558,  0.0196,  0.0145],\n",
      "        [-0.0393,  0.0050,  0.0421,  ..., -0.0477,  0.0670, -0.0471],\n",
      "        [ 0.0436, -0.1336,  0.1714,  ..., -0.0104,  0.0123, -0.0380],\n",
      "        [-0.0572,  0.0183,  0.0333,  ..., -0.0689, -0.0931, -0.0714],\n",
      "        [ 0.1578,  0.1091,  0.0737,  ...,  0.0506,  0.1057,  0.0281]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Single token embedding: tensor([ 4.3597e-02, -1.3362e-01,  1.7140e-01,  1.1383e-02, -7.4586e-02,\n",
      "        -5.1723e-02, -2.9620e-01, -5.3332e-02,  4.0742e-02, -1.2568e-01,\n",
      "         1.3112e-01,  1.3011e-01,  2.3719e-02,  2.2207e-02,  1.0508e-01,\n",
      "         3.2130e-02,  7.2995e-02, -1.0549e-02,  5.5878e-02,  1.2675e-01,\n",
      "        -9.5042e-02, -1.6710e-01,  9.8741e-03,  5.8797e-02,  3.3012e-02,\n",
      "         1.1869e-02,  8.5770e-02,  7.8617e-02,  5.4794e-02, -1.5835e-01,\n",
      "        -2.0698e-02,  1.0220e-01, -1.8902e-02,  1.8424e-01, -7.7152e-02,\n",
      "        -2.9987e-02, -3.1549e-01,  1.7471e-02,  5.3715e-02, -2.1831e-02,\n",
      "        -4.0109e-02,  1.0515e-01,  2.6298e-02,  2.5054e-03,  1.6049e-01,\n",
      "        -1.1536e-01,  1.0039e-01, -2.1206e-01,  1.7320e-01, -1.6942e-01,\n",
      "         9.9444e-02, -1.7858e-01,  6.2710e-02, -2.1736e-02, -6.2229e-02,\n",
      "        -1.3480e-01, -4.8961e-02,  9.0328e-02,  1.2681e-01,  1.5385e-01,\n",
      "        -2.5024e-01, -9.4970e-02,  1.5753e-01,  1.5363e-01,  1.7460e-01,\n",
      "        -4.2338e-02,  3.3679e-02, -1.4376e-01,  1.2436e-01,  1.6831e-02,\n",
      "        -5.1425e-02, -6.4346e-02, -4.1208e-02,  2.0668e-02,  5.5843e-02,\n",
      "         3.1982e-01, -7.5061e-03,  1.4727e-01, -1.4003e-01, -1.7186e-02,\n",
      "         7.3568e-02,  7.0826e-02,  1.4572e-01,  4.7016e-02, -2.0701e-02,\n",
      "        -2.9839e-02, -7.4763e-02,  1.7496e-01,  1.0725e-01,  3.6353e-02,\n",
      "        -9.4771e-02, -2.2090e-01,  4.9920e-02,  4.3869e-02,  1.5504e-01,\n",
      "         6.5223e-03, -4.2525e-02, -5.8362e-02, -2.0536e-01,  2.1883e-01,\n",
      "         6.6058e-02, -1.0698e-01, -2.5640e-01, -1.8944e-01,  1.0691e-01,\n",
      "        -8.1136e-02, -7.1304e-02, -2.1613e-01,  9.4080e-02,  4.9951e-02,\n",
      "        -1.6087e-02, -2.9775e-02, -2.3024e-01,  1.1790e-01, -8.8062e-02,\n",
      "        -3.8150e-02, -2.1332e-02, -1.7964e-01, -1.7891e-01,  1.1408e-01,\n",
      "         7.1811e-02,  3.3935e-02,  8.5689e-02, -3.2873e-02, -1.7297e-02,\n",
      "        -4.5023e-02,  2.0233e-03, -9.4758e-02,  6.7992e-02,  1.0945e-01,\n",
      "         4.9945e-02,  4.3694e-02, -1.5039e-01, -1.2384e-02,  9.1948e-02,\n",
      "         1.1266e-01,  8.8075e-02,  5.9859e-02, -2.2421e-01, -5.2061e-02,\n",
      "         4.0957e-02, -6.0224e-02,  2.4268e-01, -1.0379e-02,  2.4300e-01,\n",
      "        -1.5219e-01,  8.4394e-02,  8.0745e-03,  1.7202e-02,  3.9055e-03,\n",
      "         9.9987e-02,  8.4059e-02, -6.8741e-04, -5.6599e-02,  2.6486e-02,\n",
      "         7.4595e-02, -1.1989e-01, -5.4350e-02, -9.0810e-03, -1.3946e-01,\n",
      "        -1.0114e-01, -2.1051e-01, -1.1696e-01,  6.2355e-03, -2.8889e-02,\n",
      "        -3.3925e-03,  2.9405e-02,  2.1939e-01, -1.7135e-02,  1.5316e-01,\n",
      "         2.9442e-02, -3.4294e-02,  2.0070e-01,  9.9615e-02,  1.3032e-01,\n",
      "        -5.4237e-02,  1.0586e-01,  2.2374e-01, -5.6125e-02,  1.2190e-02,\n",
      "         9.2134e-02, -1.5387e-01,  3.5364e-02, -4.5619e-02, -8.3459e-02,\n",
      "         1.4435e-01,  2.2979e-01,  1.8992e-02, -3.8708e-02,  4.2480e-02,\n",
      "         8.3255e-02, -2.3242e-02, -3.8370e-03,  1.2687e-01,  5.9963e-02,\n",
      "         1.5279e-01, -7.0918e-02, -7.2420e-02,  2.3759e-01,  2.9093e-01,\n",
      "        -6.6286e-02, -5.1193e-02,  1.3496e-01, -1.4821e-01,  1.2227e-01,\n",
      "        -1.5645e-01, -2.4454e-02, -1.7331e-02, -4.6217e-02,  1.0425e-01,\n",
      "         9.0096e-02,  9.2401e-02,  1.6734e-02, -1.4762e-01,  9.8698e-02,\n",
      "         6.6406e-02, -2.0324e-01,  1.7874e-01,  5.9526e-02, -5.0915e-02,\n",
      "        -6.5592e-02, -2.8174e-02,  3.9550e-02, -4.7164e-02, -1.7228e-01,\n",
      "        -3.8690e-02, -3.3560e-01, -6.4694e-03, -9.0391e-02,  1.8667e-01,\n",
      "         2.1250e-01, -3.3493e-02, -4.1711e-01,  8.1125e-02, -1.6400e-01,\n",
      "        -6.0117e-02, -2.0784e-01,  7.0788e-02,  4.7192e-02,  8.4239e-02,\n",
      "        -7.4982e-02,  4.5065e-02,  6.0574e-02, -1.0775e-01, -2.4500e-01,\n",
      "        -3.2072e-01, -1.8574e-02,  1.6794e-01, -3.7046e-02, -4.2375e-02,\n",
      "         1.8284e-01,  1.0553e-01, -3.3714e-02,  5.4862e-02, -1.4777e-01,\n",
      "        -3.1254e-01,  1.4620e-01,  6.2282e-02, -2.1800e-01, -1.3580e-01,\n",
      "        -1.7357e-01, -1.3954e-01, -5.8067e-02,  7.9407e-02,  5.1503e-02,\n",
      "         7.7283e-02,  1.6732e-01,  3.5356e-02, -1.8380e-02,  8.6979e-02,\n",
      "         9.2343e-02, -1.3266e-01,  2.9140e-02,  9.3220e-02,  7.7499e-02,\n",
      "        -6.0675e-02, -5.2616e-02,  3.8514e-02,  4.8106e-02,  1.5812e-01,\n",
      "        -1.0241e-01,  6.9754e-02, -1.2582e-01,  9.7206e-02, -9.0327e-02,\n",
      "         1.7780e-02, -6.4840e-02, -1.2312e-01, -2.7100e-02,  8.2326e-02,\n",
      "        -1.1843e-01,  2.9819e-02,  1.4644e-01,  9.1957e-02,  9.3017e-02,\n",
      "         8.9743e-02, -1.3474e-01,  8.8963e-02,  2.4167e-01, -1.2858e-01,\n",
      "         8.0374e-03, -1.1359e-01,  1.2256e-01, -6.9762e-02,  7.7948e-03,\n",
      "        -1.2186e-01,  1.4077e-02, -1.7316e-01,  1.6140e-01, -7.7474e-02,\n",
      "        -1.8529e-01, -5.0647e-03, -1.3799e-02, -4.9072e-02,  1.7725e-01,\n",
      "        -3.6505e-02,  1.4883e-01, -8.8570e-02, -9.8001e-02,  2.2143e-01,\n",
      "         1.2524e-01,  2.1771e-01, -2.2679e-01,  3.3521e-02, -3.5566e-02,\n",
      "         5.7052e-02, -2.5736e-01,  4.2172e-02,  8.9297e-02, -4.3560e-02,\n",
      "         9.5726e-02, -3.3618e-02,  3.1749e-02, -1.9078e-01, -1.1086e-01,\n",
      "         9.6581e-02,  6.2156e-02, -1.0751e-01,  7.9970e-02,  2.0242e-02,\n",
      "         1.1373e-01,  2.5237e-01, -9.8477e-02,  2.4788e-01, -1.6697e-01,\n",
      "        -2.2609e-02, -1.1015e-01, -1.5011e-01, -1.2949e-01, -1.4852e-01,\n",
      "        -1.4302e-01, -2.5128e-01,  1.0101e-01,  1.4685e-01, -5.1308e-02,\n",
      "        -7.3568e-02,  1.0433e-01,  2.7464e-02, -4.6600e-02, -1.8882e-01,\n",
      "         4.8298e-02,  7.2565e-02, -1.7732e-01,  2.8487e-01,  4.6357e-02,\n",
      "         1.1225e-01,  6.5260e-02,  6.0255e-02,  2.0889e-02,  5.9578e-02,\n",
      "        -8.8792e-02,  6.6665e-02,  3.6051e-02,  1.6070e-01,  1.7615e-01,\n",
      "         3.7781e-02,  1.0897e-01, -1.2443e-01,  1.3190e-01, -1.8640e-02,\n",
      "         1.1145e-01, -1.0390e-02, -2.0823e-01,  8.2255e-02, -4.4803e-02,\n",
      "         5.5846e-02,  4.2638e-02, -4.8383e-02, -2.4120e-01,  1.8870e-01,\n",
      "         1.8972e-01,  3.5114e-01,  9.7557e-02, -1.3338e-02,  7.4637e-02,\n",
      "         4.6519e-02, -5.8494e-02,  1.8051e-01,  2.5126e-01,  6.9878e-02,\n",
      "        -2.4131e-01,  6.7547e-02, -4.9450e-02, -1.3525e-01, -1.9206e-01,\n",
      "        -2.1893e-02, -2.1208e-01, -1.5082e-01, -1.4430e-01, -8.1611e-02,\n",
      "         1.5321e-01,  7.7734e-02,  7.2952e-02, -5.3687e-02, -8.3114e-02,\n",
      "         3.0469e-02, -7.6117e-02, -1.0702e-01,  1.1896e-01, -1.0799e-01,\n",
      "         2.0237e-01, -4.4439e-02, -3.3666e-02, -2.5860e-01, -1.0829e-01,\n",
      "        -2.8951e-02, -2.1717e-01,  4.0778e-02, -6.1743e-04, -7.9853e-02,\n",
      "        -2.5672e-01,  8.0365e-02, -9.9545e-02, -7.4206e-02,  1.4086e-01,\n",
      "        -9.4875e-02,  9.4284e-02,  2.2311e-01,  1.1953e-01, -2.2263e-01,\n",
      "        -3.1904e-01,  2.2350e-02, -1.8700e-01,  9.6193e-02, -2.2022e-01,\n",
      "         5.9796e-02,  1.4691e-01, -1.6955e-01, -3.0914e-02,  2.7172e-02,\n",
      "        -1.2075e-01,  1.4594e-01,  6.4270e-02, -2.5835e-02, -1.6725e-01,\n",
      "        -2.3180e-01, -5.9826e-03, -2.7001e-02, -9.8108e-02, -5.1368e-02,\n",
      "         4.5529e-02, -4.2868e-02,  1.3481e-01,  1.2618e-01,  6.0816e-02,\n",
      "         5.7715e-02, -8.6009e-02,  1.0279e-01, -1.1498e-01,  1.4037e-01,\n",
      "         1.1777e-01, -1.0046e-01, -4.1548e-04,  1.9928e-01, -5.2744e-02,\n",
      "        -1.8822e-01, -2.5487e-01, -3.9519e-02,  6.7558e-02,  1.7933e-01,\n",
      "         1.8995e-01, -1.5401e-01, -1.0706e-01,  1.1534e-01,  5.1660e-02,\n",
      "         1.7470e-01, -9.4869e-02,  4.9457e-02, -1.2744e-01,  1.4353e-01,\n",
      "         1.5959e-01, -3.9165e-02,  1.0172e-01, -1.7723e-04, -1.6045e-01,\n",
      "        -2.4458e-02, -2.0557e-01,  9.4858e-02,  2.8041e-02, -1.1606e-01,\n",
      "         5.6780e-02, -1.9888e-02,  1.4434e-01,  2.6990e-01, -9.7263e-02,\n",
      "         5.3700e-02,  8.9816e-02, -2.3780e-01, -1.8541e-01, -9.8025e-02,\n",
      "        -3.9065e-02,  1.3245e-01, -1.7471e-01,  2.0549e-01, -1.1043e-01,\n",
      "         1.0982e-01, -2.2187e-01, -4.8630e-02,  2.3435e-02,  3.2269e-02,\n",
      "        -6.4590e-02,  1.6681e-01,  8.9753e-02,  3.5908e-02, -4.9704e-02,\n",
      "         5.9427e-03,  2.2267e-01,  7.7900e-02, -9.1752e-02, -1.3319e-02,\n",
      "         4.2691e-02, -8.7649e-02,  1.4677e-01,  2.6365e-01,  1.5710e-01,\n",
      "         3.2118e-02, -8.4963e-02,  1.6606e-01,  1.1215e-01, -3.3374e-02,\n",
      "        -2.0942e-01,  2.1799e-01, -1.0557e-01,  2.3891e-01, -9.3367e-02,\n",
      "         9.1251e-02, -1.1026e-01, -1.6026e-01,  1.2414e-01,  2.0087e-01,\n",
      "        -3.9207e-02,  3.4648e-02,  6.5721e-02, -1.7977e-01,  1.7005e-01,\n",
      "        -3.1332e-02,  2.1850e-01, -1.6326e-01, -1.0484e-01,  5.7953e-02,\n",
      "        -6.9441e-02,  1.4787e-01,  5.6428e-02,  3.3587e-02,  1.5950e-03,\n",
      "        -9.2349e-02, -3.1981e-02, -6.6236e-02,  6.0565e-02,  4.1924e-02,\n",
      "         3.6732e-02, -8.3211e-02,  9.7096e-02,  1.8401e-01, -4.8545e-02,\n",
      "        -9.1544e-02, -5.1289e-02, -1.3897e-01, -1.0601e-01, -1.7748e-02,\n",
      "         1.0427e-01, -2.0290e-03, -1.4857e-01, -4.4273e-02, -1.0076e-01,\n",
      "        -1.2117e-01, -5.1259e-02,  4.2942e-02, -7.3444e-02,  1.1390e-02,\n",
      "         1.2501e-01, -8.7389e-02,  4.2975e-02,  1.2822e-01, -8.3261e-03,\n",
      "         1.6926e-01, -9.7499e-02,  1.7308e-01, -1.0153e-01,  1.7442e-01,\n",
      "        -4.4853e-02, -1.2279e-02,  1.3232e-01, -1.3659e-02, -2.6102e-03,\n",
      "        -8.7881e-02,  1.9154e-02,  8.5658e-03, -1.1190e-01, -1.9126e-01,\n",
      "         2.6407e-01, -1.7860e-02, -3.6391e-02,  2.7818e-01,  1.5246e-01,\n",
      "         1.5303e-01, -1.9027e-01,  1.3678e-01,  4.7595e-01, -7.8709e-02,\n",
      "         1.1673e-01,  2.7655e-01, -1.2352e-01, -4.8056e-02,  2.5530e-01,\n",
      "        -8.2550e-02, -1.2555e-02,  1.6555e-01,  8.7571e-02, -9.9925e-02,\n",
      "         1.3638e-01, -1.3530e-01, -7.9450e-02,  8.5901e-02, -7.3679e-02,\n",
      "         2.3879e-01, -1.0986e-01, -7.5477e-02,  8.2596e-02, -1.6213e-02,\n",
      "        -1.6882e-01,  1.8504e-02, -6.1672e-02,  9.7509e-03,  1.6554e-01,\n",
      "         1.6598e-01, -2.9735e-01, -8.0422e-02,  4.1195e-02, -4.8092e-03,\n",
      "         2.7965e-02,  1.0857e-01,  1.8492e-01, -2.0631e-01,  1.4734e-01,\n",
      "        -1.7691e-01,  3.7964e-02, -6.7050e-02, -1.0259e-01, -1.8744e-01,\n",
      "         1.4763e-02, -7.0955e-03,  1.6671e-01,  1.5108e-01, -8.8821e-02,\n",
      "        -2.1063e-01, -3.8922e-02,  4.1633e-02, -1.6415e-01, -1.1083e-01,\n",
      "         1.8760e-01, -1.6794e-01, -2.6718e-02, -6.0643e-02, -1.2748e-03,\n",
      "        -6.5193e-02, -6.2194e-03,  5.3421e-02, -5.9115e-02, -1.7556e-01,\n",
      "        -5.3469e-02,  5.3870e-02, -1.1444e-01, -5.2440e-03,  2.4211e-01,\n",
      "        -1.1528e-01,  1.5097e-01,  2.9986e-02, -8.2401e-02,  1.9279e-02,\n",
      "        -1.6484e-01,  9.8852e-02,  2.4693e-01, -5.4796e-02,  5.3308e-02,\n",
      "         2.0936e-01, -1.3597e-01, -2.6381e-01,  7.7265e-02, -8.3672e-02,\n",
      "        -8.6412e-02,  8.6243e-02,  7.0617e-02,  2.5108e-01, -1.1759e-01,\n",
      "        -1.0940e-02,  3.2585e-02, -1.3221e-01,  2.0782e-02,  1.3525e-01,\n",
      "        -6.7350e-02, -1.4120e-01, -2.4380e-02, -2.5295e-01, -1.5456e-01,\n",
      "        -3.6401e-02, -1.8973e-02,  6.2039e-02, -1.7402e-01, -6.1871e-02,\n",
      "        -1.5820e-01,  1.6288e-01,  1.4455e-01, -2.2736e-01, -9.8754e-02,\n",
      "        -1.0972e-02,  6.6798e-03,  1.8388e-01,  7.9490e-02, -9.8188e-02,\n",
      "         2.1645e-01,  1.8292e-01, -8.5166e-02,  2.1371e-02, -1.3153e-01,\n",
      "         1.0616e-03, -2.8394e-02, -8.4061e-02, -3.7916e-02,  5.0850e-02,\n",
      "        -9.4862e-02,  1.1955e-01, -8.5211e-02,  5.0058e-02,  1.8354e-01,\n",
      "         1.0265e-01,  1.1881e-01,  3.6359e-02,  3.5168e-02, -1.2312e-01,\n",
      "         5.4378e-02,  1.4028e-01,  6.2341e-02, -1.9025e-02,  5.1957e-02,\n",
      "         2.4170e-02, -1.8094e-01, -4.9482e-02,  1.8893e-01,  1.3104e-01,\n",
      "        -1.0263e-01, -2.8417e-01, -1.7344e-01, -1.2002e-02, -2.5962e-01,\n",
      "        -1.0419e-02,  1.2290e-02, -3.7975e-02], grad_fn=<SelectBackward0>)\n",
      "ste shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "# Generating one token at a time\n",
    "# Step 1: Load a tokenizer and a model\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load pretrained model and tokenizer using Huggingface\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Feed a a partial sentence to the tokenizer and tokenize it\n",
    "text = \"I am the captain of my\"\n",
    "# Tokenize the text input and map tokens to token IDs from the model vocabulary and return the tensors in PyTourch (PT) format\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Retrieve the token IDs from the tokenized data dictionary\n",
    "inputs[\"input_ids\"]\n",
    "\n",
    "# convert the input text to tokens (not token IDs but the tokens)\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens) # Output: ['I', 'Ġam', 'Ġthe', 'Ġcaptain', 'Ġof', 'Ġmy'], the Ġ indicate the presense of white space\n",
    "print(inputs)\n",
    "\n",
    "embeddings = model.transformer.wte # embedding layer\n",
    "dense_vector = embeddings(inputs[\"input_ids\"]) # passing the token IDs to the embedding layer to convert each token to it respective dense vector that is 768 values that capture the\n",
    "                                               # learned values about the token including context, syntax, semantic meaning, etc\n",
    "ste = dense_vector[0,3] # fetching only the dense vector for the 4th token, 'Ġcaptain' in this case, the tensor shape would be [768] meaning 1 raw = 1 token with 768 values\n",
    "# print(f\"dense vector: {dense_vector[0]}\")\n",
    "# print(dense_vector.shape)\n",
    "# print(dense_vector)\n",
    "\n",
    "print(f\"Single token embedding: {ste}\")\n",
    "print(f\"ste shape: {ste.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the tokenizer by using pandas for visualization:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def view_tokenization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
